{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def scrape_keyword_gazeta_de_alagoas(keyword, max_page, save_path):\n",
    "\n",
    "  # Creates lists to store scraped data at each loop iteration\n",
    "  titles        = []\n",
    "  links         = []\n",
    "  dates_authors = []\n",
    "\n",
    "  scraped_data_dict = {\n",
    "                      'Titles'        : [],\n",
    "                      'Dates_Authors' : [],\n",
    "                      'Links'         : []\n",
    "                      }\n",
    "  \n",
    "  # Starts scraping loop fo given page range\n",
    "  for page in range(1, max_page):\n",
    "\n",
    "    # Creates random delays to avoid blocking\n",
    "    delay = randint(0,3)\n",
    "    print(f'Cool down of {delay}.\\nScraping page number {page}')\n",
    "    sleep(delay)\n",
    "\n",
    "    # Defines each search query URL, stores request content and creates html_doc variable for scraping\n",
    "    url      = f'https://d.gazetadealagoas.com.br/?q={keyword}&page={page}'\n",
    "    response = requests.get(url)\n",
    "    html_doc = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Tests request result. Stops loop if any error is given.\n",
    "    if str(response) != '<Response [200]>':\n",
    "      print(url); print(f\"Request error!\\n{response}\\nLoop stopped.\")\n",
    "      break\n",
    "\n",
    "    # Starts scraping if no error is given\n",
    "    else:\n",
    "      # Defines custom html content present when no results are found and defines it as stop sign to trigger loop break\n",
    "      stop_sign = html_doc.find('p', class_ = 'gza-f-roboto gza-f-22 gza-lh-25 gza-c-black-3')\n",
    "      if stop_sign == None:\n",
    "        loop = 'go'\n",
    "      else:\n",
    "        loop = 'stop'\n",
    "\n",
    "      # Breaks loop if stop sign is found\n",
    "      if loop == 'stop':\n",
    "        print(f'Found stop_sign: {stop_sign}')\n",
    "        print('Stop trigger activated.')\n",
    "        print(f'Stopped at search page {page}')\n",
    "        break\n",
    "\n",
    "      # Scrapes search result page if no stop sign is found\n",
    "      elif loop == 'go':\n",
    "        cards = html_doc.find_all('article', class_ = 'col-md-12')\n",
    "        for elem in cards:\n",
    "          # Scrapes articles titles\n",
    "          title = elem.find('h3')\n",
    "          titles.append(title.text)\n",
    "\n",
    "          # Scrapes articles dates and authors\n",
    "          date_author = elem.find('p')\n",
    "          dates_authors.append(date_author.text)\n",
    "\n",
    "          # Scrapes articles links\n",
    "          link = elem.find('a')\n",
    "          links.append(f'https://d.gazetadealagoas.com.br{link[\"href\"]}')\n",
    "\n",
    "\n",
    "  # Checks lists lengths to ensure syncing\n",
    "  a = len(titles)\n",
    "  b = len(dates_authors)\n",
    "  c = len(links)\n",
    "  print(f'Length of scraped titles list = {a}')\n",
    "  print(f'Length of scraped dates and authors list = {b}')\n",
    "  print(f'Length of scraped links list = {c}')\n",
    "  if a == b and a == c:\n",
    "    print(f'Scraped data lists with same lengths: {a} items.\\nCreating Data Frame.')\n",
    "    # Updates scraped data dict with lists and creates df\n",
    "    scraped_data_dict['Titles']        = titles\n",
    "    scraped_data_dict['Dates_Authors'] = dates_authors\n",
    "    scraped_data_dict['Links']         = links\n",
    "    scraped_data_df                    = pd.DataFrame.from_dict(scraped_data_dict)\n",
    "    scraped_data_df.to_excel(f'{save_path}\\scraping_gazeta_de_alagoas-{keyword}.xlsx', index = False )\n",
    "    return scraped_data_df\n",
    "  else :\n",
    "    print('Error!\\nLists with different lengths.\\nNo Data Frame created.')\n",
    "    return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
